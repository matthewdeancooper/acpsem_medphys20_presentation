* Presentation
** Introduction (15s)

  - The title of today's presentation is "A clinical implementation of deep
    learning: Automatic contouring via U-Net architecture".

** Limitations (51s)

   - Accurate contouring is a critical aspect of safe and effective treatment
     delivery in radiotherapy. However, there are current clinical limitations.

   - There is variance in the definition of anatomical regions between
     medical experts from imaging data. This is referred to as inter
     observer variance or IOV and is often cited as the largest source of error
     in treatment delivery.

   - The TG275 risk assessment highlights multiple
     human-factor failure modes in RT relating incorrect contouring.

   - There are also time contrasts involved in contouring and computer aided
     techniques such as deformable registration (or atlas) methods still require significant correction
     times.

   - Deep learning models have demonstrated the potential to overcome
     these limitations. When used as a starting reference they have been shown
     to reduce variance between observers and decrease total contouring time.
     They have also demonstrated significant improvements compared to atlas
     methods in both time and accuracy.

** Application (50s)

   - In an attempt to meet these limitations, this study designed a
     2D U-Net architecture with two primary aims:

   - Model 1 was designed as a QA tool for prostate cancer, we compared expert
     contours with model predictions in an attempt to alert clinical staff of
     macro contouring errors. Here we contoured patient, bladder and rectum
     volumes.

   - Model 2 was designed to automate a time consuming aspect of canine RT,
     vacuum bag segmentation. Previously, vacuum bags were delineated manually
     at clinic, at a cost of 30 minutes per patient.

   - To achieve these aims would require model performance similar to that of
     human experts. To quantify performance we used the surface dice
     coefficient, which is a metric that takes into account the variance between
     experts in its assessment. And fundamentally we are interested in this
     metric as the literature has indicated a stronger correlation with
     corrections times when compared to the traditional dice coefficient.

** sDSC vs DSC (50)

   - Now, If we compare the SURFACE dice with the traditional dice coefficient
     we see that the dice takes the intersections of two masks and returns the
     fraction of volumetric overlap.

   - In comparison the surface dice defines a boundary, adds an organ specific
     tolerance representative of IOV and return the fraction of surface points
     that are withing this tolerance and theoretically the fraction of surface
     points that would not need to be corrected manually.

** Modules required (54s)

  - In general, deep learning models share a common set of modules that can be
    broken down into data wrangling, training, and deployment stages.

  - In terms of our dataset, each model we used an average of 20 patients split
    into training, validation and testing subsets.

  - In our training stage, we made heavy use of data augmentation to increase
    the spread of our data distribution. Idea is to expose the model to
    biological deformations to produce a robust model that is invariant to
    transformation it will likely observe in the wild. We used a combination of
    linear and non-linear transformation techniques.

*** Model architecture ()
   For those that havent seen before, this is what a 2D U-Net architecture looks
   like - I only want you to get a high level overview here.

   It is composed of two primary pathways:

   1 - On the LHS we have the encoding pathway (in blue) that down-samples the resolution
   of the input at each level while increasing the number of features that have
   been extracted via convolutional operations.
   2 - On the RHS we have the decoding pathway (in yellow) that up-samples
   low resolution features, concatenates them with higher resolution features sent
   from the residual connection.

   If you remember one thing from this busy slide I want you to notice the
   pattern of decreasing the spatial resolution, recovering the spatial
   resolution, and concatenating it with higher resolution features.

   
*** Why down sample
    
   Why do we see this pattern? Goal is to facilitate
   multi-resolution analysis. Each convolutional 
   operation is limited to only a small neighbourhood of values. If you
   imagine keeping the size of a kernel constant - seen in grey -
   while reducing the resolution of the image, we are effectively increasing the
   relative size of the kernel, allowing for the extraction of spatially broader
   features (general localisation) without the memory overhead that a larger
   kernel would include. By concatenating together multi-resolution features we
   are able to detect, localise, and produce high-resolution border
   segmentation.
   
   
*** Performance
    In terms of model performance, we evaluated multiple cost functions and
    selected weighted dice as it was the only function that optimised for all
    pelvic organs. This was due to a significant pixel-wise class imbalance
    between structures. The total volume of the rectum is much smaller than the
    patient, but we the optimisation algorithm to be independent of organ size,
    so we calculate weights to give each organ equal importance.

    
** Deployment (48s)

  - In terms of model deployment, we were unable to preform inference locally at
    clinic A due to hardware constraints. Therefore, we bridged a connection to
    another clinic via an encrypted tunnel and were then able to communicate
    between sites via the DICOM networking protocol.

  - In practise, the treatment planning system exports an imaging series to a
    remote DICOM server by issuing a storage request. After storage, the server
    forwards the series to a tensorflow model that infers the contours. These
    contours are translated to a dicom rt structure file that is then forwarded
    back to the TPS by another storage request.

  - This software was designed to handle multiple requests by storings jobs in
    a thread safe queue for inference.

** Results (1.30m)

  - Provide a visual overview of the contours generated by each model and how
    they compare to experts. This is the pelvic imaging model. On the input
    image the truth is outlined in yellow and the model prediction is outlined
    in red. There is also a difference column that graphs a subtraction between
    truth and prediction.

*** Pelvic imaging model

  - For patient contours we saw excellent agreement with the worst case observed
    having a volumetric overlap score of over 99 percent.

  - With bladder contours we observed some room for improvement. A recurring
    theme of predictions was the under representation of the posterior aspect of
    large bladder examples.

  - The worst case recorded had a volumetric overlap of 67 percent, and a
    surface coefficient that indicated 30 percent of the border required manual
    correction. We suspect a broader dataset may improve performance here.

  - As for rectum contours, again, we observed some room for improvement.

  - Specifically, rectum regions containing gas were not correctly identified by
    the model. We suspect an architecture that accepts 3D input may provide the
    axial context required to interpolate the existence of the rectum in these
    cases.

    
*** Canine imaging model

  - We are now examining vacuum bag contours from the canine model and again we
    observed excellent agreement between model and expert with the lowest
    scoring contours achieving a volumetric overlap of 90 percent.

    
** Structure specific metrics (1m)

 - Quantifying average values for each organ we observed that patient and
   vacuum bag segmentation were within tolerances. Specifically the vacuum bag
   contours have been accepted clinically under the condition that they are
   verified by an RT.

 - The literature defines clinically acceptable bladder and rectum agreement to
   be a DSC greater than 0.7 - a 70 percent volume overlap. On average, were
   able achieve this. although in practise experts are able to
   achieve stronger agreement than this.

 - In each case the sDSC indicates only 10 percent of border points
   would need to be adjusted to be within the top 95th percentile of expert
   agreement. This should correlate with low corrections times for these
   contours.

 - The take home message from this slide is that while the rectum and bladder
   contours would aid clinicians as a starting reference, higher performance is
   required before they have utility in a QA tool.
