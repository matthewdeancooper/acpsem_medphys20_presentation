* Presentation
** Introduction (15s)
  - Hello everyone my name is Matthew Cooper.
  - I a am recent medical physics graduate from the university of Sydney.

  # - This project was completed in collaboration with Simon Biggs and Matthew
  #   Sobolewski from the RCCC, as well as with Yu Sun from the university of Sydney.

  - The title of this presentation is "A clinical implementation of deep
    learning: Automatic contouring via U-Net architecture".

  # - I plan to spend about 10 minutes walking through our
  #   research from clinical need to deployment.

  # - During my masters project we developed multiple contouring models
  #   and were able to
  # - A link to the supporting thesis is included on this slide as well as a video
  #   overview of the implementation hosted on the PyMedPhys documentation page.

** Limitations (51s)
   - Accurate contouring is a critical aspect of safe and effective treatment
     delivery in radiotherapy. However, there are some current limitations.

   - There exists variance between medical experts in the definition of
     anatomical regions from medical images. This is refereed to as inter
     observer variance or IOV and is often cited as the largest source of error
     in treatment delivery.
   - In addition, a 2020 AAPM task group risk assessment highlighted
     multiple human-factor failure modes in RT relating to contour generation.

   - In addition, current time contrasts from traditional atlas techniques
     are a barrier to the adoption of new technologies such as adaptive radiotherapy that
     require fast contouring

   - Recently, deep learning methods have demonstrated the potential to overcome
     these limitations with significant improvements in both time and accuracy
     and are now considered the SOTA in research.

** Application (50s)
   - In an attempt to meet these limitations, this study designed and evaluated a
     2D U-Net architecture with two primary aims:

    1) Develop a pelvic imaging quality QA tool, comparing model
       predictions with expert contours to identify macro contouring errors.
       Here we contoured patient, bladder and rectum regions.

    2) To automate a time consuming aspect of canine RT. Previously, vacuum bags
       were delineated manually with a reported completion time of 30 minutes
       per patient.

       # We focused model deployment on an animal hospital, as this was the
       # fastest way to get a product into the hands of clinicians for feedback.

    - To achieve these aims would require performance similar to human experts.
      To quantify performance we reported the surface dice similarity
      coefficient and the traditional volumetric dice similarity coefficient.

** sDSC vs DSC (50)
   - If we compare the sDSC with the DSC... The DSC is the volumetric overlap
     score between two masks. In comparison the sDSC defines a boundary, adds an
     organ specific tolerance representative of IOV and return the percentage of
     surface points that are withing this tolerance and theoretically would not
     need to be corrected

    - and the literature indicated a stronger correlation with correction
      time when compared to the traditional volumetric DSC

# ** Model architecture ()
#    For those that havent seen before, this is what a 2D U-Net architecture looks
#    like - I only want you to get a high level overview here.

#    It is composed of two primary pathways:

#    1 - On the LHS we have the encoding pathway (in blue) that down-samples the resolution
#    of the input at each level while increasing the number of features that have
#    been extracted via convolutional operations.
#    2 - On the RHS we have the decoding pathway (in yellow) that up-samples
#    low resolution features, concatenates them with higher resolution features sent
#    from the residual connection.

#    If you remember one thing from this busy slide I want you to notice the
#    pattern of decreasing the spatial resolution, recovering the spatial
#    resolution, and concatenating it with higher resolution features.


# ** Why down sample
#    1 - Reduces the total size of feature representations. Currently there are
#    hard GPU memory constraints that limit the depth, resolution, and complexity
#    of model architecture. The success in computer vision is in part due to
#    convolutional operations encoding some fundamental assumptions about our data
#    into our model and reducing the number of trainable parameters when compared
#    to fully connected networks.

#    2 - Additionally, leverage down-sampling to facilitate multi-resolution
#    analysis. If you imagine keeping the size of a convolutional kernel
#    constant - seen in grey - while reducing the resolution of the image, we are
#    effectively increasing the relative size of the kernel, allowing for the
#    extraction of spatially broader features (general localisation) without the
#    memory overhead that a larger kernel would include. By concatenating together
#    multi-resolution feature representations we are able to detect, localise, and
#    produce high-resolution border segmentation.

#    7 minutes


** Modules required (54s)

   Deep learning models share a common set of modules that can be broken down into
   data wrangling, training, and deployment stages.
   # This slide lists the steps or coding packages that we had to develop in order
   # to translate from an idea to the clinical.

   Each model we used an average of 20 patients split into training, validation
   and testing subsets.

   Made heavy use of data augmentation to increase the spread of our data distribution

   We used a 2D U-Net architecture and incorporated recent modifications that
   indicated improved performance in the literature.

   Additionally, we assessed the performance of multiple cost functions and
   selected weighted dice as it was the only loss function that optimised for
   all pelvic organs due to a significant pixel-wise class imbalance between
   structures


** Deployment (48s)

   We were unable to preform inference locally at clinic A due to hardware
   constraints. Therefore, we bridged a connection to another clinic via SSH and
   were then able to communicate between sites via the DICOM networking protocol.

   # We used pynetdicom as our networking protocol for building DICOM service
   # class users and providers. A provider includes instructions for completing a
   # task - i.e., how to store a set of images.
   # While a class user requests to utilise the functionality of a provider -
   # i.e., can you store these images.

   The treatment planning system exports an imaging series to a remote DICOM server
   by issuing a storage request. After storage, the server forwards the series to a
   tensorflow model that infers the contours. These contours are translated to a
   dicom rt structure file that is then forwarded back to the TPS by another
   storage request.

   This software was designed to handle multiple requests by storings jobs in an
   inference queue.

   --- 5m

** Results (1.30m)
   Visual overview of the contours generated by each model and how they compare
   to experts. This is the pelvic imaging model. And on the input image the
   truth is outlined in yellow and the model prediction is outlined in red.
*** Pelvic imaging model
    Patient contours we saw excellent agreement with the worst case observed
    having a volumetric overlap score of over 99 percent.

    Bladder contours we observed some room for improvement. A recurring theme of
    predictions was the under represent the posterior aspect of the bladder. The
    worst case recorded a volumetric overlap of 67 percent, with the surface
    coefficient indicating that 30 percent of the border needing manual
    correction. We suspect a broader dataset will improve performance.

    Again with rectum contours we observed some room for improvement.
    Specifically, regions containing gas were not correctly identified. We
    suspect that a 3D model may provide the axial context for interpolation and
    therefore and improve performance.

*** Canine imaging model
    Excellent agreement between model and expert with the lowest scoring
    contours achieving a volumetric overlap of 91 percent.

   --- 6.30m
** Structure specific metrics (1m)
   Both patient and vacuum bag segmentation are within tolerances. Specifically
   the vacuum bag contours have been accepted clinically.

   The literature defines clinically acceptable bladder and rectum agreement to
   be a DSC greater than 0.7 - a 70 percent volume overlap. However on average
   experts are able to achieve much better agreement than this.

   The take home message from this slide is that while these contours would aid
   clinicians as a starting reference, higher performance is required before
   they have utility in a QA tool.

   However, in each case the sDSC indicates only 10 percent of border points
   would need to be adjusted to be within the top 95th percentile of expert
   agreement. This should correlate with low corrections times.



** Conclusion and future research (1.40m)
   - Patient contours within tolerances and are viable for
     use within the QA tool.
   - Bladder and rectum contours may improve with a broader dataset.
   - SOTA implementations use an order of magnitude more data.
   - 3D implementations may improve detection - significant comp. costs involved.

  - The canine imaging model was successfully deployed to clinic under a
    prototype warning that requests manual verification. Acceptance testing has
    shown a performance improvement of 30 minutes per patient. Currently being
    utilised on all new canine patients.

 - sDSC indicated stronger correlation with correction times in lit. To minimise
   correction times we want to optimise for this directly. Currently accepts
   only binary data so a continuous surrogate is needed for gradients to
   be defined during training.

 - This field moves fast. U-Net is no longer SOTA. Under a re-implementation we
  would want to examine a new type of architecture name HR-Net.
